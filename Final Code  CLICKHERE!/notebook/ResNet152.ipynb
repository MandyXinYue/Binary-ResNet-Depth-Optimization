{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regulated-moisture",
   "metadata": {},
   "source": [
    "# Notebook used in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Tz1Ia_6CF6tS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tz1Ia_6CF6tS",
    "outputId": "747d8154-7fb1-48ee-83d6-1b51af4d8acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "U3j7nxDUF620",
   "metadata": {
    "id": "U3j7nxDUF620"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile # Om de zip te unzippen\n",
    "from google.colab import files # Om de zip te uploaden\n",
    "\n",
    "file_name = \"/content/drive/MyDrive/train+val.zip\" # Colab slaat je bestanden op in de content folder nadat je hebt geupload dit zal dus de locatie zijn van je zip bestand nadat je het hebt geupload \n",
    "\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip: \n",
    "  zip.extractall()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ydnzCKtQF7BM",
   "metadata": {
    "id": "ydnzCKtQF7BM"
   },
   "outputs": [],
   "source": [
    "file_name1 = \"/content/drive/MyDrive/test.zip\" # Colab slaat je bestanden op in de content folder nadat je hebt geupload dit zal dus de locatie zijn van je zip bestand nadat je het hebt geupload \n",
    "\n",
    "\n",
    "with ZipFile(file_name1, 'r') as zip: \n",
    "  zip.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fatty-quest",
   "metadata": {
    "id": "fatty-quest"
   },
   "outputs": [],
   "source": [
    "# disable overly verbose tensorflow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout, Flatten, Conv2D, MaxPool2D, Reshape\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# unused for now, to be used for ROC analysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "allow_growth = True\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "french-mustang",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "french-mustang",
    "outputId": "bdb6c3a9-1d75-4cc1-9290-df657c8a8318"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "_________________________________________________________________\n",
      "resnet152 (Functional)       (None, 3, 3, 2048)        58370944  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 58,372,993\n",
      "Trainable params: 58,221,569\n",
      "Non-trainable params: 151,424\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "\n",
    "input = Input(input_shape)\n",
    "\n",
    "# get the pretrained model, cut out the top layer\n",
    "pretrained = tf.keras.applications.ResNet152(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "output = pretrained(input)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "# note the lower lr compared to the cnn example\n",
    "model.compile(SGD(lr=1e-6, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# print a summary of the model on screen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "macro-charm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "macro-charm",
    "outputId": "04e97566-345c-4579-a188-2709b8d9321f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "########### insert hyperparameters ################\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "###################################################\n",
    "\n",
    "base_dir = r'/content'\n",
    "test_dir = r'/content/test'\n",
    "\n",
    "# dataset parameters\n",
    "TRAIN_PATH = os.path.join(base_dir, 'train')\n",
    "VALID_PATH = os.path.join(base_dir, 'valid')\n",
    "TEST_FILES = glob.glob(test_dir + '\\*.tif')\n",
    "RESCALING_FACTOR = 1./255\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "# instantiate data generators\n",
    "datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=train_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=True)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(VALID_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=val_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=False)\n",
    "\n",
    "# form steps\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "agreed-nepal",
   "metadata": {
    "id": "agreed-nepal"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "generous-utilization",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "generous-utilization",
    "outputId": "cdc23a28-1da9-4590-dda3-9722e3bd449c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "225/225 [==============================] - 75s 266ms/step - loss: 1.0430 - accuracy: 0.4870 - val_loss: 165.2066 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 165.20660, saving model to Resnet152_weights.hdf5\n",
      "Epoch 2/25\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.9934 - accuracy: 0.5019 - val_loss: 181.8214 - val_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 165.20660\n",
      "Epoch 3/25\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.9495 - accuracy: 0.5207 - val_loss: 62.0455 - val_accuracy: 0.0637\n",
      "\n",
      "Epoch 00003: val_loss improved from 165.20660 to 62.04555, saving model to Resnet152_weights.hdf5\n",
      "Epoch 4/25\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.9183 - accuracy: 0.5383 - val_loss: 24.2439 - val_accuracy: 0.0600\n",
      "\n",
      "Epoch 00004: val_loss improved from 62.04555 to 24.24393, saving model to Resnet152_weights.hdf5\n",
      "Epoch 5/25\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.8619 - accuracy: 0.5559 - val_loss: 11.5668 - val_accuracy: 0.3187\n",
      "\n",
      "Epoch 00005: val_loss improved from 24.24393 to 11.56678, saving model to Resnet152_weights.hdf5\n",
      "Epoch 6/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.8531 - accuracy: 0.5723 - val_loss: 3.2671 - val_accuracy: 0.4925\n",
      "\n",
      "Epoch 00006: val_loss improved from 11.56678 to 3.26712, saving model to Resnet152_weights.hdf5\n",
      "Epoch 7/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.8299 - accuracy: 0.5737 - val_loss: 2.3771 - val_accuracy: 0.5325\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.26712 to 2.37708, saving model to Resnet152_weights.hdf5\n",
      "Epoch 8/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7968 - accuracy: 0.6057 - val_loss: 2.1435 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.37708 to 2.14355, saving model to Resnet152_weights.hdf5\n",
      "Epoch 9/25\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.7649 - accuracy: 0.6068 - val_loss: 2.8762 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.14355\n",
      "Epoch 10/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7771 - accuracy: 0.5944 - val_loss: 2.3078 - val_accuracy: 0.5900\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.14355\n",
      "Epoch 11/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7429 - accuracy: 0.6270 - val_loss: 2.7818 - val_accuracy: 0.6137\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.14355\n",
      "Epoch 12/25\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.7661 - accuracy: 0.6239 - val_loss: 2.7757 - val_accuracy: 0.6338\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.14355\n",
      "Epoch 13/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7162 - accuracy: 0.6461 - val_loss: 2.3789 - val_accuracy: 0.6413\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.14355\n",
      "Epoch 14/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7252 - accuracy: 0.6540 - val_loss: 1.7854 - val_accuracy: 0.6637\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.14355 to 1.78541, saving model to Resnet152_weights.hdf5\n",
      "Epoch 15/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.7020 - accuracy: 0.6445 - val_loss: 1.8372 - val_accuracy: 0.6787\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.78541\n",
      "Epoch 16/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6779 - accuracy: 0.6645 - val_loss: 2.0562 - val_accuracy: 0.6862\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.78541\n",
      "Epoch 17/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6903 - accuracy: 0.6629 - val_loss: 2.4956 - val_accuracy: 0.6963\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.78541\n",
      "Epoch 18/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6644 - accuracy: 0.6656 - val_loss: 2.2354 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.78541\n",
      "Epoch 19/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6718 - accuracy: 0.6695 - val_loss: 1.8551 - val_accuracy: 0.7237\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.78541\n",
      "Epoch 20/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6722 - accuracy: 0.6766 - val_loss: 0.8899 - val_accuracy: 0.7513\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.78541 to 0.88993, saving model to Resnet152_weights.hdf5\n",
      "Epoch 21/25\n",
      "225/225 [==============================] - 54s 240ms/step - loss: 0.6592 - accuracy: 0.6814 - val_loss: 2.7049 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.88993\n",
      "Epoch 22/25\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.6256 - accuracy: 0.6969 - val_loss: 2.4006 - val_accuracy: 0.7437\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.88993\n",
      "Epoch 23/25\n",
      "225/225 [==============================] - 54s 241ms/step - loss: 0.6739 - accuracy: 0.6835 - val_loss: 2.7932 - val_accuracy: 0.7625\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.88993\n",
      "Epoch 24/25\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.6453 - accuracy: 0.6833 - val_loss: 2.0929 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.88993\n",
      "Epoch 25/25\n",
      "225/225 [==============================] - 54s 242ms/step - loss: 0.6234 - accuracy: 0.7093 - val_loss: 2.4353 - val_accuracy: 0.7725\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.88993\n"
     ]
    }
   ],
   "source": [
    "# save the model and weights\n",
    "model_name = 'Resnet152'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model, note that we define \"mini-epochs\"\n",
    "train_steps = train_gen.n//train_gen.batch_size//20\n",
    "val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=25,\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "welsh-silence",
   "metadata": {
    "id": "welsh-silence"
   },
   "outputs": [],
   "source": [
    "pip install -U keras-tuner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loaded-appendix",
   "metadata": {
    "id": "loaded-appendix"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "available-enterprise",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "available-enterprise",
    "outputId": "a872463b-3fb5-42c3-f423-5c4b0287e41f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc2bce6fc50>]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
    "\n",
    "#Assigning the first subplot to graph training loss and validation loss\n",
    "ax[0].plot(model.history.history['loss'],color='b',label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'],color='r',label='Validation Loss')\n",
    "\n",
    "#Plotting the training accuracy and validation accuracy\n",
    "ax[1].plot(model.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
    "ax[1].plot(model.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "advanced-committee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "advanced-committee",
    "outputId": "fbafea18-dbb6-41f0-d983-06d6bc3ce081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 0 - 5000\n",
      "Indexes: 5000 - 10000\n",
      "Indexes: 10000 - 15000\n",
      "Indexes: 15000 - 20000\n",
      "Indexes: 20000 - 25000\n",
      "Indexes: 25000 - 30000\n",
      "Indexes: 30000 - 35000\n",
      "Indexes: 35000 - 40000\n",
      "Indexes: 40000 - 45000\n",
      "Indexes: 45000 - 50000\n",
      "Indexes: 50000 - 55000\n",
      "Indexes: 55000 - 60000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "#Change these variables to point at the locations and names of the test dataset and your models.\n",
    "TEST_PATH = r\"/content/test\"\n",
    "MODEL_FILEPATH = 'Resnet152.json' \n",
    "MODEL_WEIGHTS_FILEPATH = 'Resnet152_weights.hdf5'\n",
    "\n",
    "# load model and model weights\n",
    "json_file = open(MODEL_FILEPATH, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(MODEL_WEIGHTS_FILEPATH)\n",
    "\n",
    "\n",
    "# open the test set in batches (as it is a very big dataset) and make predictions\n",
    "test_files = glob.glob(TEST_PATH + '/*.tif')\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "\n",
    "    print('Indexes: %i - %i'%(idx, idx+file_batch))\n",
    "\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "\n",
    "\n",
    "    # get the image id \n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split(os.sep)[-1].split('.')[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    \n",
    "    \n",
    "    K_test = np.stack(test_df['image'].values)\n",
    "    \n",
    "    # apply the same preprocessing as during draining\n",
    "    K_test = K_test.astype('float')/255.0\n",
    "    \n",
    "    predictions = model.predict(K_test)\n",
    "    \n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[['id', 'label']]])\n",
    "\n",
    "\n",
    "# save your submission\n",
    "submission.head()\n",
    "submission.to_csv('submission_resnet152.csv', index = False, header = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "capable-shadow",
   "metadata": {
    "id": "capable-shadow"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet152.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
