{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kerastuner\n",
    "kerastuner.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from resnets_utils import *\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "from kerastuner.tuners import RandomSearch, Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block): \n",
    "        \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2a', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "        \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters = F1,kernel_size = (f, f), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters = F2, kernel_size = (3, 3), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = he_normal(seed=None))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape=(96, 96, 3), classes=1):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256,256,1024], stage=4, block='b')\n",
    "        \n",
    "    \n",
    "\n",
    "    # AVGPOOL (â‰ˆ1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = he_normal(seed=None))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    model.compile(SGD(lr=1e-6, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(SGD(lr=0.001, momentum=0.95), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "########### insert hyperparameters ################\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "###################################################\n",
    "base_dir = r'data'\n",
    "test_dir = r'data\\test'\n",
    "\n",
    "# dataset parameters\n",
    "TRAIN_PATH = os.path.join(base_dir, 'train')\n",
    "VALID_PATH = os.path.join(base_dir, 'valid')\n",
    "TEST_FILES = glob.glob(test_dir + '\\*.tif')\n",
    "RESCALING_FACTOR = 1./255\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "# instantiate data generators\n",
    "datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=train_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=True)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(VALID_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=val_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=False)\n",
    "\n",
    "# form steps\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner = Hyperband(\n",
    "#    build_model,\n",
    "#    overwrite=True,\n",
    "#    objective='val_accuracy',\n",
    "#    max_epochs = 15,\n",
    "#    factor = 2,\n",
    "#    hyperband_iterations=1,\n",
    "#    directory ='storage/ResnetTuner_s',\n",
    "#    project_name='ResNet_Stage1234_s'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner.search(train_gen,\n",
    "#             verbose=2, \n",
    "#             epochs=25,\n",
    "#             batch_size=32,\n",
    "#             steps_per_epoch=train_steps,\n",
    "#             callbacks=[stop_early],\n",
    "#             validation_steps=val_steps,\n",
    "#             validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4500/4500 [==============================] - 159s 34ms/step - loss: 0.6810 - accuracy: 0.5985 - val_loss: 0.5765 - val_accuracy: 0.7118\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.57652, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 2/25\n",
      "4500/4500 [==============================] - 155s 34ms/step - loss: 0.5737 - accuracy: 0.7123 - val_loss: 0.5316 - val_accuracy: 0.7428\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.57652 to 0.53158, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 3/25\n",
      "4500/4500 [==============================] - 154s 34ms/step - loss: 0.5357 - accuracy: 0.7389 - val_loss: 0.5100 - val_accuracy: 0.7577\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53158 to 0.51004, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 4/25\n",
      "4500/4500 [==============================] - 155s 34ms/step - loss: 0.5207 - accuracy: 0.7472 - val_loss: 0.4987 - val_accuracy: 0.7645\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.51004 to 0.49866, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 5/25\n",
      "4500/4500 [==============================] - 154s 34ms/step - loss: 0.5111 - accuracy: 0.7546 - val_loss: 0.4917 - val_accuracy: 0.7683\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49866 to 0.49172, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 6/25\n",
      "4500/4500 [==============================] - 153s 34ms/step - loss: 0.5010 - accuracy: 0.7621 - val_loss: 0.4870 - val_accuracy: 0.7707\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49172 to 0.48704, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 7/25\n",
      "4500/4500 [==============================] - 154s 34ms/step - loss: 0.5009 - accuracy: 0.7628 - val_loss: 0.4832 - val_accuracy: 0.7726\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.48704 to 0.48324, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 8/25\n",
      "4500/4500 [==============================] - 154s 34ms/step - loss: 0.4943 - accuracy: 0.7648 - val_loss: 0.4790 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.48324 to 0.47904, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 9/25\n",
      "4500/4500 [==============================] - 153s 34ms/step - loss: 0.4901 - accuracy: 0.7668 - val_loss: 0.4757 - val_accuracy: 0.7753\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.47904 to 0.47574, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 10/25\n",
      "4500/4500 [==============================] - 153s 34ms/step - loss: 0.4860 - accuracy: 0.7693 - val_loss: 0.4719 - val_accuracy: 0.7778\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47574 to 0.47195, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 11/25\n",
      "4500/4500 [==============================] - 154s 34ms/step - loss: 0.4841 - accuracy: 0.7708 - val_loss: 0.4685 - val_accuracy: 0.7786\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.47195 to 0.46852, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 12/25\n",
      "4500/4500 [==============================] - 153s 34ms/step - loss: 0.4801 - accuracy: 0.7737 - val_loss: 0.4656 - val_accuracy: 0.7819\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.46852 to 0.46556, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 13/25\n",
      "4500/4500 [==============================] - 144s 32ms/step - loss: 0.4800 - accuracy: 0.7725 - val_loss: 0.4625 - val_accuracy: 0.7834\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.46556 to 0.46254, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 14/25\n",
      "4500/4500 [==============================] - 135s 30ms/step - loss: 0.4758 - accuracy: 0.7749 - val_loss: 0.4603 - val_accuracy: 0.7852\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.46254 to 0.46027, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 15/25\n",
      "4500/4500 [==============================] - 132s 29ms/step - loss: 0.4705 - accuracy: 0.7788 - val_loss: 0.4578 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.46027 to 0.45783, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 16/25\n",
      "4500/4500 [==============================] - 149s 33ms/step - loss: 0.4686 - accuracy: 0.7797 - val_loss: 0.4551 - val_accuracy: 0.7884\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.45783 to 0.45505, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 17/25\n",
      "4500/4500 [==============================] - 156s 35ms/step - loss: 0.4644 - accuracy: 0.7821 - val_loss: 0.4527 - val_accuracy: 0.7892\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.45505 to 0.45275, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 18/25\n",
      "4500/4500 [==============================] - 158s 35ms/step - loss: 0.4623 - accuracy: 0.7828 - val_loss: 0.4503 - val_accuracy: 0.7919\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.45275 to 0.45031, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 19/25\n",
      "4500/4500 [==============================] - 156s 35ms/step - loss: 0.4632 - accuracy: 0.7825 - val_loss: 0.4490 - val_accuracy: 0.7918\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.45031 to 0.44897, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 20/25\n",
      "4500/4500 [==============================] - 155s 34ms/step - loss: 0.4589 - accuracy: 0.7868 - val_loss: 0.4479 - val_accuracy: 0.7930\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.44897 to 0.44787, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 21/25\n",
      "4500/4500 [==============================] - 154s 34ms/step - loss: 0.4563 - accuracy: 0.7883 - val_loss: 0.4457 - val_accuracy: 0.7944\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.44787 to 0.44572, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 22/25\n",
      "4500/4500 [==============================] - 155s 34ms/step - loss: 0.4544 - accuracy: 0.7871 - val_loss: 0.4439 - val_accuracy: 0.7951\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.44572 to 0.44393, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 23/25\n",
      "4500/4500 [==============================] - 158s 35ms/step - loss: 0.4534 - accuracy: 0.7886 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.44393 to 0.44267, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 24/25\n",
      "4500/4500 [==============================] - 157s 35ms/step - loss: 0.4480 - accuracy: 0.7931 - val_loss: 0.4412 - val_accuracy: 0.7961\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.44267 to 0.44123, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Epoch 25/25\n",
      "4500/4500 [==============================] - 156s 35ms/step - loss: 0.4492 - accuracy: 0.7918 - val_loss: 0.4397 - val_accuracy: 0.7972\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.44123 to 0.43966, saving model to ResNet_Stage1234_s_weights.hdf5\n",
      "Best epoch: 25\n"
     ]
    }
   ],
   "source": [
    "# save the model and weights\n",
    "model_name = 'ResNet_Stage1234_s'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json) \n",
    "    \n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_gen, \n",
    "          epochs = 25, \n",
    "          batch_size = 32, \n",
    "          steps_per_epoch=train_steps,\n",
    "          validation_data=val_gen,\n",
    "          validation_steps=val_steps,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "#hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 102, 102, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 48, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 23, 23, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 21, 21, 64)   36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 21, 21, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 21, 21, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 21, 21, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 21, 21, 64)   36928       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 21, 21, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 21, 21, 64)   256         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 21, 21, 64)   0           bn2a_branch2b[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 21, 21, 64)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 21, 21, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 21, 21, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 21, 21, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 21, 21, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 21, 21, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 21, 21, 64)   0           bn2b_branch2b[0][0]              \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 21, 21, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 21, 21, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 21, 21, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 21, 21, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 21, 21, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 21, 21, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 21, 21, 64)   0           bn2c_branch2b[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 21, 21, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 10, 10, 128)  73856       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 10, 10, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 10, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 10, 10, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 10, 10, 128)  73856       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 10, 10, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 10, 10, 128)  512         res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 10, 10, 128)  0           bn3a_branch2b[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 10, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 10, 10, 128)  147584      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 10, 10, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 10, 10, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 10, 10, 128)  147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 10, 10, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 10, 10, 128)  0           bn3b_branch2b[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 10, 10, 128)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 10, 10, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 10, 10, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 10, 10, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 10, 10, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 10, 10, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 10, 10, 128)  0           bn3c_branch2b[0][0]              \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 10, 10, 128)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 10, 10, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 10, 10, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 10, 10, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 10, 10, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 10, 10, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 10, 10, 128)  0           bn3d_branch2b[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 10, 10, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 4, 4, 256)    295168      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 4, 4, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 4, 4, 256)    295168      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 4, 4, 256)    1024        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 4, 4, 256)    0           bn4a_branch2b[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 4, 4, 256)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 4, 4, 256)    590080      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 4, 4, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 4, 4, 256)    590080      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 4, 4, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 256)    0           bn4b_branch2b[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 4, 4, 256)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 2, 2, 256)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1)            1025        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,822,145\n",
      "Trainable params: 3,816,257\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 5000 - 10000\n",
      "Indexes: 10000 - 15000\n",
      "Indexes: 15000 - 20000\n",
      "Indexes: 20000 - 25000\n",
      "Indexes: 25000 - 30000\n",
      "Indexes: 30000 - 35000\n",
      "Indexes: 35000 - 40000\n",
      "Indexes: 40000 - 45000\n",
      "Indexes: 45000 - 50000\n",
      "Indexes: 50000 - 55000\n",
      "Indexes: 55000 - 60000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imread\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "#Change these variables to point at the locations and names of the test dataset and your models.\n",
    "TEST_PATH = r'data/test/'\n",
    "MODEL_FILEPATH = 'ResNet_Stage1234_s.json' \n",
    "MODEL_WEIGHTS_FILEPATH = 'ResNet_Stage1234_s_weights.hdf5'\n",
    "\n",
    "# load model and model weights\n",
    "json_file = open(MODEL_FILEPATH, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(MODEL_WEIGHTS_FILEPATH)\n",
    "\n",
    "# open the test set in batches (as it is a very big dataset) and make predictions\n",
    "test_files = glob.glob(TEST_PATH + '*')\n",
    "print(test_files)\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "\n",
    "    print('Indexes: %i - %i'%(idx, idx+file_batch))\n",
    "\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "\n",
    "\n",
    "    # get the image id \n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split(os.sep)[-1].split('.')[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    \n",
    "    \n",
    "    K_test = np.stack(test_df['image'].values)\n",
    "    \n",
    "    # apply the same preprocessing as during draining\n",
    "    K_test = K_test.astype('float')/255.0\n",
    "    \n",
    "    predictions = model.predict(K_test)\n",
    "    \n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[['id', 'label']]])\n",
    "\n",
    "\n",
    "# save your submission\n",
    "submission.head()\n",
    "submission.to_csv('submission_ResNet_Stage1234_s.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
