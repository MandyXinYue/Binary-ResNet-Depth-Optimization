{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "from kerastuner.tuners import RandomSearch, Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 3\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = he_normal(seed=None))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (96, 96, 3)\n",
    "classes = 1\n",
    "\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block='a', s=2)\n",
    "    for i in range(hp.Int('n_IDblocks', 1, 61)):\n",
    "        X = identity_block(X, 3, [128,128,512], stage=3, block=f'_{i}_')\n",
    "    \n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = he_normal(seed=None))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    model.compile(SGD(lr=1e-6, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ResNet50(input_shape = (96, 96, 3), classes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(SGD(lr=0.001, momentum=0.95), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "########### insert hyperparameters ################\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "###################################################\n",
    "\n",
    "base_dir = r'data'\n",
    "test_dir = r'data\\test'\n",
    "\n",
    "# dataset parameters\n",
    "TRAIN_PATH = os.path.join(base_dir, 'train')\n",
    "VALID_PATH = os.path.join(base_dir, 'valid')\n",
    "TEST_FILES = glob.glob(test_dir + '\\*.tif')\n",
    "RESCALING_FACTOR = 1./255\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "# instantiate data generators\n",
    "datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=train_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=True)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(VALID_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=val_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=False)\n",
    "\n",
    "# form steps\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    overwrite=True,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs = 25,\n",
    "    factor = 5,\n",
    "    directory ='ResnetTuner_L',\n",
    "    project_name='ResNet_Stage123_L'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 Complete [02h 24m 47s]\n",
      "val_accuracy: 0.7854999899864197\n",
      "\n",
      "Best val_accuracy So Far: 0.8085625171661377\n",
      "Total elapsed time: 21h 27m 15s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_gen,\n",
    "             verbose=2, \n",
    "             epochs=25,\n",
    "             batch_size=32,\n",
    "             steps_per_epoch=train_steps,\n",
    "             callbacks=[stop_early],\n",
    "             validation_steps=val_steps,\n",
    "             validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<kerastuner.engine.hyperparameters.HyperParameters object at 0x7f4894458bb0>\n"
     ]
    }
   ],
   "source": [
    "print(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4500/4500 [==============================] - 184s 40ms/step - loss: 0.6215 - accuracy: 0.6641 - val_loss: 0.5162 - val_accuracy: 0.7568\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.51625, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 2/25\n",
      "4500/4500 [==============================] - 176s 39ms/step - loss: 0.5265 - accuracy: 0.7494 - val_loss: 0.5014 - val_accuracy: 0.7649\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.51625 to 0.50139, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 3/25\n",
      "4500/4500 [==============================] - 174s 39ms/step - loss: 0.5141 - accuracy: 0.7553 - val_loss: 0.4906 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50139 to 0.49060, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 4/25\n",
      "4500/4500 [==============================] - 168s 37ms/step - loss: 0.5038 - accuracy: 0.7605 - val_loss: 0.4834 - val_accuracy: 0.7750\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49060 to 0.48338, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 5/25\n",
      "4500/4500 [==============================] - 169s 38ms/step - loss: 0.4946 - accuracy: 0.7660 - val_loss: 0.4775 - val_accuracy: 0.7784\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48338 to 0.47745, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 6/25\n",
      "4500/4500 [==============================] - 169s 37ms/step - loss: 0.4885 - accuracy: 0.7686 - val_loss: 0.4707 - val_accuracy: 0.7808\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47745 to 0.47069, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 7/25\n",
      "4500/4500 [==============================] - 168s 37ms/step - loss: 0.4840 - accuracy: 0.7697 - val_loss: 0.4662 - val_accuracy: 0.7832\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47069 to 0.46619, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 8/25\n",
      "4500/4500 [==============================] - 168s 37ms/step - loss: 0.4734 - accuracy: 0.7768 - val_loss: 0.4626 - val_accuracy: 0.7834\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.46619 to 0.46262, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 9/25\n",
      "4500/4500 [==============================] - 170s 38ms/step - loss: 0.4730 - accuracy: 0.7773 - val_loss: 0.4568 - val_accuracy: 0.7878\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.46262 to 0.45682, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 10/25\n",
      "4500/4500 [==============================] - 168s 37ms/step - loss: 0.4711 - accuracy: 0.7791 - val_loss: 0.4548 - val_accuracy: 0.7912\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.45682 to 0.45481, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 11/25\n",
      "4500/4500 [==============================] - 166s 37ms/step - loss: 0.4659 - accuracy: 0.7824 - val_loss: 0.4490 - val_accuracy: 0.7946\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.45481 to 0.44896, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 12/25\n",
      "4500/4500 [==============================] - 170s 38ms/step - loss: 0.4616 - accuracy: 0.7834 - val_loss: 0.4465 - val_accuracy: 0.7956\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.44896 to 0.44650, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 13/25\n",
      "4500/4500 [==============================] - 168s 37ms/step - loss: 0.4580 - accuracy: 0.7869 - val_loss: 0.4431 - val_accuracy: 0.7963\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.44650 to 0.44306, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 14/25\n",
      "4500/4500 [==============================] - 169s 38ms/step - loss: 0.4538 - accuracy: 0.7880 - val_loss: 0.4406 - val_accuracy: 0.7973\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.44306 to 0.44056, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 15/25\n",
      "4500/4500 [==============================] - 169s 37ms/step - loss: 0.4488 - accuracy: 0.7916 - val_loss: 0.4395 - val_accuracy: 0.8014\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.44056 to 0.43953, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 16/25\n",
      "4500/4500 [==============================] - 208s 46ms/step - loss: 0.4453 - accuracy: 0.7937 - val_loss: 0.4367 - val_accuracy: 0.8023\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.43953 to 0.43666, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 17/25\n",
      "4500/4500 [==============================] - 213s 47ms/step - loss: 0.4467 - accuracy: 0.7933 - val_loss: 0.4348 - val_accuracy: 0.8021\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.43666 to 0.43485, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 18/25\n",
      "4500/4500 [==============================] - 170s 38ms/step - loss: 0.4412 - accuracy: 0.7952 - val_loss: 0.4322 - val_accuracy: 0.8029\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.43485 to 0.43222, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 19/25\n",
      "4500/4500 [==============================] - 167s 37ms/step - loss: 0.4437 - accuracy: 0.7936 - val_loss: 0.4307 - val_accuracy: 0.8043\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.43222 to 0.43075, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 20/25\n",
      "4500/4500 [==============================] - 170s 38ms/step - loss: 0.4395 - accuracy: 0.7957 - val_loss: 0.4293 - val_accuracy: 0.8045\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.43075 to 0.42932, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 21/25\n",
      "4500/4500 [==============================] - 170s 38ms/step - loss: 0.4370 - accuracy: 0.7988 - val_loss: 0.4279 - val_accuracy: 0.8051\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.42932 to 0.42793, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 22/25\n",
      "4500/4500 [==============================] - 171s 38ms/step - loss: 0.4333 - accuracy: 0.8004 - val_loss: 0.4269 - val_accuracy: 0.8046\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.42793 to 0.42693, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 23/25\n",
      "4500/4500 [==============================] - 171s 38ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.4247 - val_accuracy: 0.8056\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.42693 to 0.42467, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 24/25\n",
      "4500/4500 [==============================] - 171s 38ms/step - loss: 0.4311 - accuracy: 0.8020 - val_loss: 0.4230 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.42467 to 0.42304, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Epoch 25/25\n",
      "4500/4500 [==============================] - 171s 38ms/step - loss: 0.4303 - accuracy: 0.8024 - val_loss: 0.4221 - val_accuracy: 0.8071\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.42304 to 0.42214, saving model to ResNet_Stage123_L_weights.hdf5\n",
      "Best epoch: 25\n"
     ]
    }
   ],
   "source": [
    "# save the model and weights\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model_name = 'ResNet_Stage123_L'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json) \n",
    "    \n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_gen, \n",
    "          epochs = 25, \n",
    "          batch_size = 32, \n",
    "          steps_per_epoch=train_steps,\n",
    "          validation_data=val_gen,\n",
    "          validation_steps=val_steps,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 102, 102, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 48, 48, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 48, 48, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 23, 23, 64)   0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 23, 23, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 23, 23, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 23, 23, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 23, 23, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 23, 23, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 23, 23, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 23, 23, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 23, 23, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 23, 23, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 23, 23, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 23, 23, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 23, 23, 64)   16448       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 23, 23, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 23, 23, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 23, 23, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 23, 23, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 23, 23, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 23, 23, 256)  16640       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 23, 23, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 23, 23, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 23, 23, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 12, 12, 128)  32896       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 12, 12, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 12, 12, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 12, 12, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 12, 12, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 12, 12, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 12, 12, 512)  66048       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 12, 12, 512)  131584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 12, 12, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 12, 12, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 12, 12, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 12, 12, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3_0__branch2a (Conv2D)       (None, 12, 12, 128)  65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3_0__branch2a (BatchNormaliza (None, 12, 12, 128)  512         res3_0__branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 12, 12, 128)  0           bn3_0__branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_0__branch2b (Conv2D)       (None, 12, 12, 128)  147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3_0__branch2b (BatchNormaliza (None, 12, 12, 128)  512         res3_0__branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 12, 12, 128)  0           bn3_0__branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_0__branch2c (Conv2D)       (None, 12, 12, 512)  66048       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3_0__branch2c (BatchNormaliza (None, 12, 12, 512)  2048        res3_0__branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 12, 12, 512)  0           bn3_0__branch2c[0][0]            \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 12, 12, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3_1__branch2a (Conv2D)       (None, 12, 12, 128)  65664       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3_1__branch2a (BatchNormaliza (None, 12, 12, 128)  512         res3_1__branch2a[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 12, 12, 128)  0           bn3_1__branch2a[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_1__branch2b (Conv2D)       (None, 12, 12, 128)  147584      activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3_1__branch2b (BatchNormaliza (None, 12, 12, 128)  512         res3_1__branch2b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 12, 12, 128)  0           bn3_1__branch2b[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "res3_1__branch2c (Conv2D)       (None, 12, 12, 512)  66048       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3_1__branch2c (BatchNormaliza (None, 12, 12, 512)  2048        res3_1__branch2c[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 12, 12, 512)  0           bn3_1__branch2c[0][0]            \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 12, 12, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 6, 6, 512)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 18432)        0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1)            18433       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,196,161\n",
      "Trainable params: 1,187,585\n",
      "Non-trainable params: 8,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "#hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 5000 - 10000\n",
      "Indexes: 10000 - 15000\n",
      "Indexes: 15000 - 20000\n",
      "Indexes: 20000 - 25000\n",
      "Indexes: 25000 - 30000\n",
      "Indexes: 30000 - 35000\n",
      "Indexes: 35000 - 40000\n",
      "Indexes: 40000 - 45000\n",
      "Indexes: 45000 - 50000\n",
      "Indexes: 50000 - 55000\n",
      "Indexes: 55000 - 60000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TU/e BME Project Imaging 2021\n",
    "Submission code for Kaggle PCAM\n",
    "Author: Suzanne Wetstein\n",
    "'''\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "#Change these variables to point at the locations and names of the test dataset and your models.\n",
    "TEST_PATH = r'data/test/' \n",
    "MODEL_FILEPATH = 'ResNet_Stage123_L.json' \n",
    "MODEL_WEIGHTS_FILEPATH = 'ResNet_Stage123_L_weights.hdf5'\n",
    "\n",
    "# load model and model weights\n",
    "json_file = open(MODEL_FILEPATH, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(MODEL_WEIGHTS_FILEPATH)\n",
    "\n",
    "\n",
    "# open the test set in batches (as it is a very big dataset) and make predictions\n",
    "test_files = glob.glob(TEST_PATH + '*')\n",
    "print(test_files)\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "\n",
    "    print('Indexes: %i - %i'%(idx, idx+file_batch))\n",
    "\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "\n",
    "\n",
    "    # get the image id \n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split(os.sep)[-1].split('.')[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    \n",
    "    \n",
    "    K_test = np.stack(test_df['image'].values)\n",
    "    \n",
    "    # apply the same preprocessing as during draining\n",
    "    K_test = K_test.astype('float')/255.0\n",
    "    \n",
    "    predictions = model.predict(K_test)\n",
    "    \n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[['id', 'label']]])\n",
    "\n",
    "\n",
    "# save your submission\n",
    "submission.head()\n",
    "submission.to_csv('submission_ResNet_Stage123_L.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
