{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kerastuner\n",
    "kerastuner.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/8p361-lecturer/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:434: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from resnets_utils import *\n",
    "from tensorflow.keras.initializers import he_normal\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "from kerastuner.tuners import RandomSearch, Hyperband\n",
    "from kerastuner.engine.hyperparameters import HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block): \n",
    "        \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2a', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "        \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(filters = F1,kernel_size = (f, f), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path \n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv2D(filters = F2, kernel_size = (3, 3), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
    "                        kernel_initializer = he_normal(seed=None))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet(input_shape=(96, 96, 3), classes=1):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=he_normal(seed=None))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='m')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='n')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[128,128,512], stage=3, block='a', s=2)\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='d')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='e')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='f')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='g')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='h')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='i')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='j')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='k')\n",
    "    X = identity_block(X, 3, [128,128,512], stage=3, block='l')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[256,256,1024], stage=4, block='a', s=2)\n",
    "    X = identity_block(X, 3, [256,256,1024], stage=4, block='o')\n",
    "    X = identity_block(X, 3, [256,256,1024], stage=4, block='p')\n",
    "    \n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[512,512,2048], stage=5, block='a', s=2)\n",
    "    X = identity_block(X, 3, [512,512,2048], stage=5, block='q')\n",
    "    X = identity_block(X, 3, [512,512,2048], stage=5, block='r') \n",
    "    \n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = he_normal(seed=None))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    model.compile(SGD(lr=1e-6, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(SGD(lr=0.001, momentum=0.95), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "########### insert hyperparameters ################\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "###################################################\n",
    "base_dir = r'data'\n",
    "test_dir = r'data\\test'\n",
    "\n",
    "# dataset parameters\n",
    "TRAIN_PATH = os.path.join(base_dir, 'train')\n",
    "VALID_PATH = os.path.join(base_dir, 'valid')\n",
    "TEST_FILES = glob.glob(test_dir + '\\*.tif')\n",
    "RESCALING_FACTOR = 1./255\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "# instantiate data generators\n",
    "datagen = ImageDataGenerator(rescale=RESCALING_FACTOR)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(TRAIN_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=train_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=True)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(VALID_PATH,\n",
    "                                    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                    batch_size=val_batch_size,\n",
    "                                    class_mode='binary',\n",
    "                                    shuffle=False)\n",
    "\n",
    "# form steps\n",
    "train_steps = train_gen.n//train_gen.batch_size\n",
    "val_steps = val_gen.n//val_gen.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner = Hyperband(\n",
    "#    build_model,\n",
    "#    overwrite=True,\n",
    "#    objective='val_accuracy',\n",
    "#    max_epochs = 15,\n",
    "#    factor = 2,\n",
    "#    hyperband_iterations=1,\n",
    "#    directory ='storage/ResnetTuner_s',\n",
    "#    project_name='ResNet_Stage1234_s'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuner.search(train_gen,\n",
    "#             verbose=2, \n",
    "#             epochs=25,\n",
    "#             batch_size=32,\n",
    "#             steps_per_epoch=train_steps,\n",
    "#             callbacks=[stop_early],\n",
    "#             validation_steps=val_steps,\n",
    "#             validation_data=val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4500/4500 [==============================] - 243s 52ms/step - loss: 0.8488 - accuracy: 0.5661 - val_loss: 0.6394 - val_accuracy: 0.6924\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63935, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 2/25\n",
      "4500/4500 [==============================] - 233s 52ms/step - loss: 0.6558 - accuracy: 0.6860 - val_loss: 0.5773 - val_accuracy: 0.7256\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63935 to 0.57734, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 3/25\n",
      "4500/4500 [==============================] - 234s 52ms/step - loss: 0.6045 - accuracy: 0.7119 - val_loss: 0.5477 - val_accuracy: 0.7433\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57734 to 0.54774, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 4/25\n",
      "4500/4500 [==============================] - 238s 53ms/step - loss: 0.5760 - accuracy: 0.7279 - val_loss: 0.5351 - val_accuracy: 0.7456\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54774 to 0.53506, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 5/25\n",
      "4500/4500 [==============================] - 235s 52ms/step - loss: 0.5613 - accuracy: 0.7354 - val_loss: 0.5204 - val_accuracy: 0.7561\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.53506 to 0.52037, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 6/25\n",
      "4500/4500 [==============================] - 233s 52ms/step - loss: 0.5467 - accuracy: 0.7415 - val_loss: 0.5112 - val_accuracy: 0.7602\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52037 to 0.51118, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 7/25\n",
      "4500/4500 [==============================] - 223s 50ms/step - loss: 0.5379 - accuracy: 0.7478 - val_loss: 0.5029 - val_accuracy: 0.7640\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51118 to 0.50289, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 8/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.5283 - accuracy: 0.7514 - val_loss: 0.4973 - val_accuracy: 0.7694\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.50289 to 0.49733, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 9/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.5264 - accuracy: 0.7508 - val_loss: 0.4909 - val_accuracy: 0.7702\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.49733 to 0.49086, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 10/25\n",
      "4500/4500 [==============================] - 209s 46ms/step - loss: 0.5187 - accuracy: 0.7570 - val_loss: 0.4859 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49086 to 0.48590, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 11/25\n",
      "4500/4500 [==============================] - 213s 47ms/step - loss: 0.5111 - accuracy: 0.7605 - val_loss: 0.4822 - val_accuracy: 0.7756\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.48590 to 0.48223, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 12/25\n",
      "4500/4500 [==============================] - 212s 47ms/step - loss: 0.5089 - accuracy: 0.7596 - val_loss: 0.4783 - val_accuracy: 0.7781\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.48223 to 0.47834, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 13/25\n",
      "4500/4500 [==============================] - 212s 47ms/step - loss: 0.5068 - accuracy: 0.7593 - val_loss: 0.4780 - val_accuracy: 0.7755\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.47834 to 0.47798, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 14/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.5028 - accuracy: 0.7615 - val_loss: 0.4748 - val_accuracy: 0.7795\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.47798 to 0.47479, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 15/25\n",
      "4500/4500 [==============================] - 213s 47ms/step - loss: 0.4964 - accuracy: 0.7664 - val_loss: 0.4752 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47479\n",
      "Epoch 16/25\n",
      "4500/4500 [==============================] - 212s 47ms/step - loss: 0.4968 - accuracy: 0.7658 - val_loss: 0.4692 - val_accuracy: 0.7818\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.47479 to 0.46923, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 17/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.4922 - accuracy: 0.7681 - val_loss: 0.4669 - val_accuracy: 0.7844\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.46923 to 0.46689, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 18/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.4922 - accuracy: 0.7668 - val_loss: 0.4652 - val_accuracy: 0.7850\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.46689 to 0.46520, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 19/25\n",
      "4500/4500 [==============================] - 212s 47ms/step - loss: 0.4847 - accuracy: 0.7714 - val_loss: 0.4655 - val_accuracy: 0.7881\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.46520\n",
      "Epoch 20/25\n",
      "4500/4500 [==============================] - 210s 47ms/step - loss: 0.4823 - accuracy: 0.7709 - val_loss: 0.4624 - val_accuracy: 0.7866\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.46520 to 0.46241, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 21/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.4812 - accuracy: 0.7738 - val_loss: 0.4612 - val_accuracy: 0.7861\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.46241 to 0.46116, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 22/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.4810 - accuracy: 0.7736 - val_loss: 0.4606 - val_accuracy: 0.7880\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.46116 to 0.46061, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 23/25\n",
      "4500/4500 [==============================] - 211s 47ms/step - loss: 0.4817 - accuracy: 0.7717 - val_loss: 0.4592 - val_accuracy: 0.7893\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.46061 to 0.45918, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 24/25\n",
      "4500/4500 [==============================] - 210s 47ms/step - loss: 0.4758 - accuracy: 0.7744 - val_loss: 0.4568 - val_accuracy: 0.7926\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.45918 to 0.45679, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Epoch 25/25\n",
      "4500/4500 [==============================] - 219s 49ms/step - loss: 0.4737 - accuracy: 0.7783 - val_loss: 0.4550 - val_accuracy: 0.7913\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.45679 to 0.45502, saving model to ResNet_Stage12345_s_weights.hdf5\n",
      "Best epoch: 24\n"
     ]
    }
   ],
   "source": [
    "# save the model and weights\n",
    "model_name = 'ResNet_Stage12345_s'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json) \n",
    "    \n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "# fit model\n",
    "history = model.fit(train_gen, \n",
    "          epochs = 25, \n",
    "          batch_size = 32, \n",
    "          steps_per_epoch=train_steps,\n",
    "          validation_data=val_gen,\n",
    "          validation_steps=val_steps,\n",
    "          callbacks=callbacks_list)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "#hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 5000 - 10000\n",
      "Indexes: 10000 - 15000\n",
      "Indexes: 15000 - 20000\n",
      "Indexes: 20000 - 25000\n",
      "Indexes: 25000 - 30000\n",
      "Indexes: 30000 - 35000\n",
      "Indexes: 35000 - 40000\n",
      "Indexes: 40000 - 45000\n",
      "Indexes: 45000 - 50000\n",
      "Indexes: 50000 - 55000\n",
      "Indexes: 55000 - 60000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}   \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imread\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "#Change these variables to point at the locations and names of the test dataset and your models.\n",
    "TEST_PATH = r'data/test/'\n",
    "MODEL_FILEPATH = 'ResNet_Stage12345_s.json' \n",
    "MODEL_WEIGHTS_FILEPATH = 'ResNet_Stage12345_s_weights.hdf5'\n",
    "\n",
    "# load model and model weights\n",
    "json_file = open(MODEL_FILEPATH, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "model.load_weights(MODEL_WEIGHTS_FILEPATH)\n",
    "\n",
    "# open the test set in batches (as it is a very big dataset) and make predictions\n",
    "test_files = glob.glob(TEST_PATH + '*')\n",
    "print(test_files)\n",
    "submission = pd.DataFrame()\n",
    "\n",
    "file_batch = 5000\n",
    "max_idx = len(test_files)\n",
    "\n",
    "for idx in range(0, max_idx, file_batch):\n",
    "\n",
    "    print('Indexes: %i - %i'%(idx, idx+file_batch))\n",
    "\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]})\n",
    "\n",
    "\n",
    "    # get the image id \n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split(os.sep)[-1].split('.')[0])\n",
    "    test_df['image'] = test_df['path'].map(imread)\n",
    "    \n",
    "    \n",
    "    K_test = np.stack(test_df['image'].values)\n",
    "    \n",
    "    # apply the same preprocessing as during draining\n",
    "    K_test = K_test.astype('float')/255.0\n",
    "    \n",
    "    predictions = model.predict(K_test)\n",
    "    \n",
    "    test_df['label'] = predictions\n",
    "    submission = pd.concat([submission, test_df[['id', 'label']]])\n",
    "\n",
    "\n",
    "# save your submission\n",
    "submission.head()\n",
    "submission.to_csv('submission_ResNet_Stage12345_s.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
